{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9bd7df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import types\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "df = pd.read_csv('General_Files/train.csv')\n",
    "df = df.sort_values('SalePrice',ascending=True)\n",
    "df = df.drop(['Id'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65de0dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Execution_Pipeline:\n",
    "    method_list = []\n",
    "    \n",
    "    def add(self, method:types.FunctionType):\n",
    "        already_exists = False\n",
    "        for f in self.method_list:\n",
    "            already_exists = f.__name__ == method.__name__\n",
    "        \n",
    "        if not already_exists:\n",
    "            self.method_list.append(method)\n",
    "    \n",
    "    def exec_pipe(self,parameter:pd.DataFrame):\n",
    "        try:\n",
    "            for f in self.method_list:\n",
    "                f(parameter)\n",
    "                \n",
    "        except Exception as e:\n",
    "            return e\n",
    "        \n",
    "pipe = Execution_Pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3a8802",
   "metadata": {},
   "source": [
    "### Extracting the Indexes of Columns to Action Groups of we will work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f6a9465",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_std=['YearBuilt','YearRemodAdd','BsmtFinSF2','BsmtUnfSF','TotalBsmtSF','1stFlrSF','2ndFlrSF','LowQualFinSF','GrLivArea','HalfBath','GarageArea','WoodDeckSF','OpenPorchSF','EnclosedPorch','3SsnPorch','ScreenPorch','PoolArea']\n",
    "cols_norm=['LotArea','BsmtFinSF1','BsmtFullBath','BsmtHalfBath','FullBath','BedroomAbvGr','KitchenAbvGr','TotRmsAbvGrd','Fireplaces','GarageCars','MiscVal','MoSold','YrSold','OverallQual', 'OverallCond']\n",
    "cols_cat=['MSSubClass','MSZoning','LotShape','LotConfig','RoofStyle','MasVnrType','ExterQual','BsmtExposure','HeatingQC','KitchenQual','GarageType','Neighborhood','HouseStyle','Exterior1st','Exterior2nd','Foundation','BsmtQual','BsmtFinType1','FireplaceQu','GarageFinish']\n",
    "cols_NA = ['BsmtExposure','GarageType','BsmtQual','BsmtFinType1','FireplaceQu','GarageFinish']\n",
    "\n",
    "all_cols = cols_std + cols_norm + cols_cat\n",
    "aux = df[all_cols].copy()\n",
    "\n",
    "nums_idx, cat_idx, std_idx, norm_idx, na_idx = [],[],[],[],[]\n",
    "\n",
    "for c in aux.columns:\n",
    "    if df[c].dtype == 'O':\n",
    "        cat_idx+=[aux.columns.get_loc(c)]\n",
    "    else:\n",
    "        nums_idx+=[aux.columns.get_loc(c)]\n",
    "        if c in cols_std:\n",
    "            std_idx+=[aux.columns.get_loc(c)]\n",
    "        else:\n",
    "            norm_idx+=[aux.columns.get_loc(c)]\n",
    "    if c in cols_NA:\n",
    "        na_idx+=[aux.columns.get_loc(c)]\n",
    "\n",
    "x = df[all_cols].copy().values\n",
    "y = df['SalePrice'].copy().values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c754f2b",
   "metadata": {},
   "source": [
    "### Separando conjunto de teste e treino\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e91b5bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f92587",
   "metadata": {},
   "source": [
    "### Transforming MSSubClass to categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3fc561b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type before convertion is object. Now MSSubClass data type is object\n"
     ]
    }
   ],
   "source": [
    "before = x_train[:, cat_idx[0]].dtype\n",
    "\n",
    "def procedure_01(dataframe):\n",
    "    dataframe[ :, cat_idx[0] ] = dataframe[:, cat_idx[0]].astype(str)\n",
    "   \n",
    "pipe.add(procedure_01)\n",
    "\n",
    "procedure_01(x_train)\n",
    "print('Type before convertion is {}. Now MSSubClass data type is {}'.format(before, x_train[:, cat_idx[0]].dtype))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb8d77a",
   "metadata": {},
   "source": [
    "### Transforming nan values to 'NA' data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ae9d598",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "These is columns with 'NA' values after convertion:\n",
      "\tidx39: ['Av' 'Gd' 'Mn' 'NA' 'No']\n",
      "\tidx42: ['2Types' 'Attchd' 'Basment' 'BuiltIn' 'CarPort' 'Detchd' 'NA']\n",
      "\tidx48: ['Ex' 'Fa' 'Gd' 'NA' 'TA']\n",
      "\tidx49: ['ALQ' 'BLQ' 'GLQ' 'LwQ' 'NA' 'Rec' 'Unf']\n",
      "\tidx50: ['Ex' 'Fa' 'Gd' 'NA' 'Po' 'TA']\n",
      "\tidx51: ['Fin' 'NA' 'RFn' 'Unf']\n"
     ]
    }
   ],
   "source": [
    "      \n",
    "def procedure_02(dataframe):\n",
    "    dataframe[:,na_idx] = pd.DataFrame(dataframe[:,na_idx]).fillna('NA').values\n",
    "\n",
    "pipe.add(procedure_02)\n",
    "procedure_02(x_train)\n",
    "\n",
    "print(\"\\nThese is columns with 'NA' values after convertion:\")\n",
    "for col in na_idx:\n",
    "    print('\\tidx{}: {}'.format(col, np.unique(x_train[:,col])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ac0bfe",
   "metadata": {},
   "source": [
    "### Applying procedures of standardization, normalization, missing values treatment and one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a95c1c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoding_Steps:\n",
    "    encoders={}\n",
    "    imputers={}\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.encoders['std'] = StandardScaler()\n",
    "        self.encoders['norm'] = MinMaxScaler()\n",
    "        self.encoders['hot'] = ColumnTransformer(transformers=[('encoder', OneHotEncoder(handle_unknown='ignore'),cat_idx)], remainder='passthrough')\n",
    "        self.imputers['numerical'] = SimpleImputer(missing_values=np.nan,strategy='median')\n",
    "        self.imputers['categorical'] = SimpleImputer(missing_values=np.nan,strategy='most_frequent')\n",
    "        \n",
    "    \n",
    "    def procedure_03_train(self,dataframe):\n",
    "        dataframe[:,nums_idx] = self.imputers['numerical'].fit_transform(dataframe[:,nums_idx])\n",
    "        dataframe[:,cat_idx] = self.imputers['categorical'].fit_transform(dataframe[:,cat_idx])\n",
    "    \n",
    "    def procedure_03_test(self,dataframe):\n",
    "        dataframe[:,nums_idx] = self.imputers['numerical'].transform(dataframe[:,nums_idx])\n",
    "        dataframe[:,cat_idx] = self.imputers['categorical'].transform(dataframe[:,cat_idx])\n",
    "        \n",
    "    def procedure_04_train(self,dataframe):\n",
    "        dataframe[:,std_idx]= self.encoders['std'].fit_transform(dataframe[:,std_idx])\n",
    "        dataframe[:,norm_idx] = self.encoders['norm'].fit_transform(dataframe[:,norm_idx])\n",
    "    \n",
    "    def procedure_04_test(self,dataframe):\n",
    "        dataframe[:,std_idx]= self.encoders['std'].transform(dataframe[:,std_idx])\n",
    "        dataframe[:,norm_idx] = self.encoders['norm'].transform(dataframe[:,norm_idx])\n",
    "    \n",
    "    def procedure_05_train(self,dataframe):\n",
    "        return self.encoders['hot'].fit_transform(dataframe).toarray()\n",
    "        \n",
    "    def procedure_05_test(self,dataframe):\n",
    "        return self.encoders['hot'].transform(dataframe).toarray()\n",
    "        \n",
    "encoding_steps = Encoding_Steps()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f475ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3: missing values treatment -> median and most_frequent imputers\n",
    "encoding_steps.procedure_03_train(x_train)\n",
    "pipe.add(encoding_steps.procedure_03_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35f6404e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step4: standardize and normalize process\n",
    "encoding_steps.procedure_04_train(x_train)\n",
    "pipe.add(encoding_steps.procedure_04_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50317fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step5: one hot encoding\n",
    "x_train = encoding_steps.procedure_05_train(x_train)\n",
    "pipe.add(encoding_steps.procedure_05_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ff2cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "poly_reg = PolynomialFeatures(degree = 3)\n",
    "x_poly = poly_reg.fit_transform(x_train)\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(x_poly, y_train)\n",
    "\n",
    "plt.scatter(x_train, y_train, color = 'red')\n",
    "plt.plot(x_train, lin_reg_2.predict(poly_reg.fit_transform(x_train)), color = 'blue')\n",
    "plt.title('Truth or Bluff (Polynomial Regression)')\n",
    "plt.xlabel('Position level')\n",
    "plt.ylabel('Salary')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b4ac1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e275b2e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c6aef0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d632bc02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c70159",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fef1dc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38562ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
